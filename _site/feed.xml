<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/henry.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/henry.github.io/" rel="alternate" type="text/html" /><updated>2024-07-21T16:09:49+08:00</updated><id>http://localhost:4000/henry.github.io/feed.xml</id><title type="html">My Approximation</title><subtitle>&quot;在终极的分析中，一切知识都是历史；在抽象的意义下，一切科学都是数学；在理性的基础上，所有的判断都是统计学&quot;。
&lt;br&gt;
“All models are wrong, but some are useful&quot; -- George E.P.Box
</subtitle><entry xml:lang="zh"><title type="html">《长安的荔枝》随笔</title><link href="http://localhost:4000/henry.github.io/blog/2024/07/21/01/" rel="alternate" type="text/html" title="《长安的荔枝》随笔" /><published>2024-07-21T15:00:00+08:00</published><updated>2024-07-21T15:00:00+08:00</updated><id>http://localhost:4000/henry.github.io/blog/2024/07/21/01</id><content type="html" xml:base="http://localhost:4000/henry.github.io/blog/2024/07/21/01/"><![CDATA[<h2 id="前言">前言</h2>
<p>刚刚看完了《长安的荔枝》，真的是一部非常有意思的小说。很少有小说我一看完马上就想随笔记下几笔的，但这部小说真的很好看。这里我也不想做什么分析，读后感之类的，既然是随笔，那我就想到什么就写什么。</p>

<h2 id="这部小说一定要拍成电影">这部小说一定要拍成电影！</h2>
<p>虽然我不懂什么制片，导演什么。但是我认为这部小说镜头感和画面感真的非常强。所有的情节我在阅读时，脑海中都是一副副的画面，人物的情绪，强烈的冲突，有快有慢的节奏感，这个小说真是一部好的剧本。比如李善德在酒醉后那滑稽的一摔，然后吃惊的发现圣旨上圣人要的是新鲜荔枝而非煎荔枝，那夸张的表情和肢体动作，我在阅读时连如何运镜都已经想好了。</p>
<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0721_03.JPG" alt="Image 1" />
</div>

<h2 id="科研六步法">科研六步法</h2>
<p>李善德的荔枝转运法简直是现代科研的教科书模版。</p>
<ol>
  <li><b>文献占有，理论研究</b> - 通过大量的地图阅读，线路研究，李善德先在纸上完成了理论线路的规划和对时间的模拟。</li>
  <li><b>实地考察，修正理论</b> - 去到荔枝原产地进行实地考察，并了解荔枝保鲜的土方法，然后对理论进行修正。</li>
  <li><b>模拟实验，收集数据</b> - 李善德将四种理论进行了横向的实验对比，并收集实验数据，通过表格筛选出两种最优方案。</li>
  <li><b>再次文献占有，实地调查</b> - 当理论遇到瓶颈，李善德再次进行大量的书籍阅读，并进行了实地调查，然后通过折枝法再次延长荔枝保鲜时间。</li>
  <li><b>理论成立，经费申报</b> - 当理论成立，由于需要大量的人力财力，李善德向杨国忠提交了”项目计划书”以及经费的申报.</li>
  <li><b>项目实施，备用预案</b> - 项目开始启动，很多未知的风险和挑战，李善德的备用预案确保了项目最后的成功。
<br /></li>
</ol>

<p>这六部教科书般的步骤真的值得每个搞科研的人研究。就第二步，80%搞科研的人都难以做到。</p>

<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0721_01.JPG" alt="Image 2" />
</div>

<h2 id="不禁一笑">不禁一笑</h2>
<p>最后我不想去讨论这个书的主题，什么“凭君莫话封侯事， 一将功成万骨枯” 的批判， 或是 “一骑红尘妃子笑，无人知是荔枝来”的讽刺。
<br /></p>

<p>我只是昨天刚好在外面旅游，当我开着车在夕阳下从南往北，而这条高速的尽头正是西安。<b>看着远处连绵的山脉，我不禁一笑，我是该同情主人公在官场的无奈，还是他生错了时代？</b></p>

<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0721_02.JPG" alt="Image 3" />
</div>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[前言 刚刚看完了《长安的荔枝》，真的是一部非常有意思的小说。很少有小说我一看完马上就想随笔记下几笔的，但这部小说真的很好看。这里我也不想做什么分析，读后感之类的，既然是随笔，那我就想到什么就写什么。]]></summary></entry><entry xml:lang="zh"><title type="html">从西班牙浅析现代足球发展</title><link href="http://localhost:4000/henry.github.io/blog/2024/07/16/01/" rel="alternate" type="text/html" title="从西班牙浅析现代足球发展" /><published>2024-07-16T17:00:00+08:00</published><updated>2024-07-16T17:00:00+08:00</updated><id>http://localhost:4000/henry.github.io/blog/2024/07/16/01</id><content type="html" xml:base="http://localhost:4000/henry.github.io/blog/2024/07/16/01/"><![CDATA[<div class="quote-box">
  <p>前言</p>
</div>
<p>因为要一早去办事，无缘昨晚凌晨三点的欧洲杯决赛。但是，其实我并不担心西班牙，因为英格兰确实没那个实力跟西班牙争冠。我这不是马后炮，在欧洲杯开赛以前我就成功预测了四强，半决赛乃至最后的冠军 - 朋友建议我开通一个足球竞猜咨询服务（一场10块）。</p>
<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0716_1.JPG" alt="Image 1" />
</div>

<div class="quote-box">
  <p>效率和务实依然是现代足球的核心</p>
</div>
<p>在2018年法国赢得世界杯时，我曾写过一篇博客，指出现代足球的核心是追求效率和务实。法国队通过防守反击的策略，建立坚固的阵地防守，减少中场过度控球与传递，反击时迅速将球从后场打到前场。这种策略的成功使得越来越多的队伍青睐这种打法。然而，不知何时，欧洲足球在追求务实和效率上走上了极端，认为法国的这种快速直传是唯一的解决之道。</p>

<div class="quote-box">
  <p>直和快一定不是足球的最优解</p>
</div>
<p>如果将足球比赛看作非完全信息博弈，那么必然不只有一种方法可以达到最优解。在我看来，巅峰时期的传控足球也是对效率和务实的追求。每一次跑动和传球虽然并不是最快和最直接的，但都是为了高效地拉扯出空间，务实地创造机会。俗话说物极必反，这几年欧洲足球在过度追求效率和务实的过程中，完全放弃了中场，对球员脚下技术的要求越来越低，导致了如今的比赛越来越“难看”。</p>

<div class="quote-box">
  <p>可以不用传控，但不能没有传控</p>
</div>
<p>在权威网站“Soccer Training Solutions”上的一篇文章提到：“传球是最快和最有效的方式来移动球，它能让队友参与进来，突破防守，并创造得分机会。伟大的球队和球员在传球方面表现出色。接球（包括第一次触球）对于流畅地控制球并进行下一步动作至关重要。” 因此，传球和接球是足球运动最基本的基本功。如今的西班牙在无效传控和极致务实之间找到了一个稳定的平衡点。</p>

<p>反击时，西班牙队通常只需1～2脚精准的传接球便可将球从中场传递到前场，这是对效率的足球。而在需要控制比赛节奏的时候（例如在领先时），球队可以从容地将球控制在脚下，因为他们从未忘记对脚下技术的打磨。正所谓“善战者，动如雷霆，不动如山”，这体现了孙子兵法中的智慧，也说明了传控足球在现代足球中的重要性。</p>

<div class="quote-box">
  <p>总结</p>
</div>
<p>现代足球的发展不能忽视传控足球的价值。效率和务实固然重要，但过度追求简单粗暴的打法会让比赛失去应有的美感和平衡。西班牙足球展示了如何在务实和传控之间找到平衡，这种智慧和技术的结合，是现代足球发展的重要方向。</p>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[前言 因为要一早去办事，无缘昨晚凌晨三点的欧洲杯决赛。但是，其实我并不担心西班牙，因为英格兰确实没那个实力跟西班牙争冠。我这不是马后炮，在欧洲杯开赛以前我就成功预测了四强，半决赛乃至最后的冠军 - 朋友建议我开通一个足球竞猜咨询服务（一场10块）。]]></summary></entry><entry xml:lang="zh"><title type="html">非线性动力学的识别 (SINDy) 于时间序列数据</title><link href="http://localhost:4000/henry.github.io/create/2024/07/12/01/" rel="alternate" type="text/html" title="非线性动力学的识别 (SINDy) 于时间序列数据" /><published>2024-07-12T20:00:00+08:00</published><updated>2024-07-12T20:00:00+08:00</updated><id>http://localhost:4000/henry.github.io/create/2024/07/12/01</id><content type="html" xml:base="http://localhost:4000/henry.github.io/create/2024/07/12/01/"><![CDATA[<div class="quote-box">
  <p><b>介绍</b></p>
</div>

<p>本项目采用稀疏非线性动力学识别（SINDy）算法，从与流体和气体动力学相关的三种特征的时间序列数据中识别出控制方程。数据来自我之前题为“<a href="/henry.github.io/assets/papers/Backpropagation.pdf">使用结构化学习方法增强时间序列数据中的特征预测</a>”的项目。分析的三种特征是：输出1处的流体速度、输出1处的气体质量流量和输出2处的气体速度。利用SINDy算法，我们通过构建候选函数库、使用稀疏回归识别最相关的项，并将识别出的方程与观测数据进行验证，重建这些特征的底层数学模型。该项目展示了SINDy在从复杂的时间序列数据中发现简单、可解释模型方面的有效性，增强了我们对流体和气体动力学的理解。</p>

<div class="quote-box">
  <p><b>模型解释：稀疏非线性动力学识别（SINDy）算法</b></p>
</div>

<p>稀疏非线性动力学识别（SINDy）是一种旨在利用候选函数库中的少量项来描述动力系统的简约模型的算法。该方法结合了稀疏回归原理和系统化的非线性函数库，从时间序列数据中识别系统的控制方程。</p>

<h3 id="数学公式">数学公式</h3>

<p>考虑一个由常微分方程（ODE）描述的动力系统：</p>

\[\frac{d\mathbf{x}}{dt} = \mathbf{f}(\mathbf{x})\]

<p>其中，\(\mathbf{x} \in \mathbb{R}^n\) 是系统的状态向量，\(\mathbf{f}\) 代表非线性动力学。</p>

<p>SINDy的目标是通过预定义库中的候选函数的稀疏线性组合来近似函数\(\mathbf{f}\)。这个过程包括以下步骤：</p>

<ol>
  <li>
    <p><strong>数据收集</strong>：
收集状态变量\(\mathbf{x}(t)\)的时间序列数据。令\(\mathbf{X}\)为包含这些测量值的矩阵，其中每列对应一个不同的状态变量，每行对应一个不同的时间点。</p>
  </li>
  <li>
    <p><strong>库构建</strong>：
构建一个候选函数库\(\mathbf{\Theta}(\mathbf{X})\)。该库包括状态变量的各种非线性函数，如多项式、三角函数和指数函数。从数学上讲，该库可以表示为：</p>

\[\mathbf{\Theta}(\mathbf{X}) = [\mathbf{1}, \mathbf{X}, \mathbf{X}^2, \sin(\mathbf{X}), \cos(\mathbf{X}), \exp(\mathbf{X}), \mathbf{X} \exp(\mathbf{X}), \ldots],\]

    <p>其中\(\mathbf{\Theta}\)的每一列代表一个不同的候选函数。</p>
  </li>
  <li>
    <p><strong>稀疏回归</strong>：
对于每个状态变量\(x_i\)，将时间导数\(\frac{dx_i}{dt}\)表示为候选函数\(\mathbf{\Theta}(\mathbf{X})\)的线性组合：</p>

\[\frac{d\mathbf{X}}{dt} = \mathbf{\Theta}(\mathbf{X}) \mathbf{\Xi},\]

    <p>其中\(\mathbf{\Xi}\)是系数矩阵，每列对应一个不同的状态变量。关键思想是在\(\mathbf{\Xi}\)中施加稀疏性，即大多数系数应为零。可以使用稀疏回归技术如最小绝对收缩和选择算子（LASSO）来实现：</p>

\[\mathbf{\Xi} = \underset{\mathbf{\Xi}}{\operatorname{argmin}} \left\| \frac{d\mathbf{X}}{dt} - \mathbf{\Theta}(\mathbf{X}) \mathbf{\Xi} \right\|_2^2 + \lambda \left\| \mathbf{\Xi} \right\|_1,\]

    <p>其中\(\lambda\)是控制解稀疏性的正则化参数。</p>
  </li>
  <li>
    <p><strong>模型识别</strong>：
系数矩阵\(\mathbf{\Xi}\)中的非零项对应于库\(\mathbf{\Theta}(\mathbf{X})\)中最能描述系统动力学的项。识别出的模型可以写成：</p>

\[\frac{dx_i}{dt} = \sum_{j} \xi_{ij} \theta_j(\mathbf{x}),\]

    <p>其中\(\xi_{ij}\)是非零系数，\(\theta_j(\mathbf{x})\)是对应的候选函数。</p>
  </li>
</ol>

<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0711_1.JPG" alt="Image 1" />
   <br />
   <div class="caption">应用于洛伦兹等式的SINDy算法概略图</div>
</div>

<p>总之，SINDy提供了一个强大的框架，可以从数据中识别控制方程，通过稀疏和可解释的模型提供对复杂系统动力学的洞察。你可以在<a href="https://www.pnas.org/doi/pdf/10.1073/pnas.1517384113">这里</a>阅读原始的SINDy论文。</p>

<div class="quote-box">
  <p><b>数据处理</b></p>
</div>

<h3 id="初步处理">初步处理</h3>

<p>本项目分析的数据源自之前的机器学习项目，题为<a href="/henry.github.io/assets/papers/Backpropagation.pdf">“使用结构化学习方法增强时间序列数据中的特征预测”</a>。该项目旨在使用不同模型的组合建立所选特征\(X = (X_1, X_2)\)与目标特征\(Y = (Y_1, Y_2, Y_3)\)之间的统计关系。学习架构包括三个主要阶段：初始预测、残差训练和模型优化。通过这种参数聚焦的方法，我们获得了目标特征的预测\(Y_{\text{final}}\)，其相对均方误差（MSE）为0.0005。然而，这些数值预测缺乏解释和数学推理，特别是在最后阶段，我们使用了多层感知器（MLP），这种模型常被批评为“黑箱”。</p>

<p>因此，在本项目中，我希望使用SINDy为这些结果构建控制方程的近似。虽然近似的控制方程可能无法提供与数值模型一样准确的结果，但我希望它们能为结果提供更多的数学推理，并增强我们对流体和气体动力学的理解。</p>

<p>当前SINDy项目分析的三种特征是：</p>

<ol>
  <li>
    <p><strong>输出1处的流体速度</strong>：该特征表示流体在第一个输出点的移动速度。理解系统内流体流动的动态和行为至关重要。</p>
  </li>
  <li>
    <p><strong>输出1处的气体质量流量</strong>：该特征测量单位时间内通过第一个输出点的气体质量。评估系统内气体传输的效率和性能至关重要。</p>
  </li>
  <li>
    <p><strong>输出2处的气体速度</strong>：该特征表示第二个输出点的气体流动速度。了解气体动力学行为对优化和控制气体相关过程至关重要。</p>
  </li>
</ol>

<p>这些特征在一系列时间步长中记录，生成了三列时间序列数据。</p>

<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0711_2.JPG" alt="Image 2" />
   <br />
   <div class="caption">三个特征的时间序列图</div>
</div>

<h3 id="候选选择">候选选择</h3>

<p>为了识别这三种特征的控制方程，我们构建了一个候选函数库。所选择的候选函数旨在捕捉系统内可能的多种动态。该库包括：</p>

<ol>
  <li>
    <p><strong>常数项</strong>：表示所有时间步长中的常数值，捕捉数据中的任何基线水平。该项有助于解释数据中的任何稳态行为或偏移。</p>
  </li>
  <li>
    <p><strong>线性项 \(t\)</strong>：捕捉数据随时间的任何线性趋势。该项对于识别值的任何稳定增加或减少非常重要，这可能对应于系统中的一致加速或减速。</p>
  </li>
  <li>
    <p><strong>二次项 \(t^2\)</strong>：解释数据中的任何二次或抛物线趋势。该项对于建模随时间变化的加速或减速非常有用，通常出现在经历非线性增长或衰减的系统中。</p>
  </li>
  <li>
    <p><strong>指数项 \(\exp(-t)\)</strong>：建模指数衰减，这是许多物理和化学过程中常见的，例如放射性衰变、冷却或机械系统中的阻尼。随着\(t\)增加，该函数的形状迅速减小到零，非常适合捕捉随时间减少的过程。</p>
  </li>
  <li>
    <p><strong>正弦项 \(\sin(t)\)</strong>：捕捉数据中的周期性振荡或循环，通常出现在具有谐波运动的系统中，如波动、振动或季节性变化。正弦函数对于识别规律间隔重复的循环行为非常有价值。</p>
  </li>
  <li>
    <p><strong>余弦项 \(\cos(t)\)</strong>：补充正弦项，捕捉相位移的周期性行为。正弦项从零开始，而余弦项从一开始，使得捕捉不同相位的振荡行为成为可能。</p>
  </li>
  <li>
    <p><strong>交互项 \(t \cdot \exp(-t)\)</strong>：表示线性和指数动力学的组合，用于建模系统中更复杂的交互。这一项从零开始，增加到峰值，然后衰减，适合建模随时间最初增长然后衰减的过程。</p>
  </li>
</ol>

<p>这些候选函数被选择用来提供一个全面且相对简单的基础，以近似控制方程。当然，您可以选择尽可能多的复杂项来获得更接近的近似；然而，在可解释性和过拟合之间的选择是微妙的。</p>

<div class="quote-box">
  <p><b>网络设置和训练</b></p>
</div>

<ol>
  <li>
    <p><strong>库构建</strong>：
为每个特征构建候选函数库。该库包括常数、线性、二次、指数、正弦、余弦和交互项。这些候选函数被选择用来捕捉系统内可能的多种动态。</p>
  </li>
  <li><strong>数据分割</strong>：
每个特征的数据分为三个区间：
    <ul>
      <li>区间1：\(t \in [0, 10)\)</li>
      <li>区间2：\(t \in [10, 600)\)</li>
      <li>区间3：\(t \in [600, 2000]\)</li>
    </ul>

    <p>将数据分割成这些区间可以捕捉不同时间段内可能发生的不同动态行为。每个区间单独处理，以确保识别出的控制方程特定于该区间内的动态，从而更准确和详细地理解系统随时间的行为。</p>
  </li>
  <li><strong>稀疏回归</strong>：
使用LassoCV算法（一种L1正则化线性回归）来拟合数据。这个过程包括：
    <ul>
      <li>对候选函数进行缩放以标准化数据。</li>
      <li>执行交叉验证以确定最优正则化参数(\(\lambda\))。</li>
      <li>识别控制方程中最显著项的系数，确保生成的模型既稀疏又可解释。</li>
    </ul>
  </li>
  <li><strong>方程构建</strong>：
对于每个区间和每个特征，将识别出的系数和项结合形成控制方程。这些分段方程提供了该区间内动力学的详细数学表示，通过揭示驱动观测行为的底层过程，增强了我们对流体和气体动力学的理解。</li>
</ol>

<div class="quote-box">
  <p><b>实验结果</b></p>
</div>

<p>实验结果显示在下图中：</p>

<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0711_3.JPG" alt="Image 3" />
   <br />
   <div class="caption">识别出的控制方程及其对应的图与实际结果对比</div>
</div>

<p>实验结果将每个特征的实际时间序列数据与使用SINDy算法得出的控制方程进行比较。分析的三个特征是：<i>输出1处的流体速度</i>、<i>输出1处的气体质量流量</i>和<i>输出2处的气体速度</i>。</p>

<p>总体而言，识别出的方程捕捉到了实际数据的总体趋势和动态行为。SINDy算法通过选择控制方程中的有限数量的显著项，成功地平衡了简单性（可解释性）和准确性（避免过拟合）。这种平衡确保了模型在提供对底层动力学的良好近似的同时仍然可解释。</p>

<p>在图中，识别出的分段方程与实际数据一起呈现。这些方程提供了系统在每个区间内行为的详细数学表示。尽管在某些区间，识别出的数据与实际数据之间存在一些偏差，但总体拟合度很强，展示了SINDy方法在捕捉流体和气体行为的基本动力学方面的有效性。</p>

<div class="quote-box">
  <p><b>结论</b></p>
</div>

<p>在本项目中，我们应用稀疏非线性动力学识别（SINDy）算法识别了来自之前机器学习项目的时间序列数据的控制方程。本研究中出现了几个关键点和反思：</p>

<ol>
  <li>
    <p><strong>候选选择是关键</strong>：
选择适当的候选函数来构建库是SINDy最关键的部分。库直接影响识别方程的有效性和准确性。一个选择良好的库可以让模型在保持可解释性的同时捕捉系统的基本动态。</p>
  </li>
  <li>
    <p><strong>系统的先验知识</strong>：
SINDy的成功在很大程度上依赖于对系统的先验知识，以选择正确的候选函数。这在现实世界中可能面临挑战，因为数据的背景信息可能有限或不可用。在这种情况下，SINDy的有效性仍然是一个未解的问题，强调了对算法进一步研究和潜在改进的需求。</p>
  </li>
  <li>
    <p><strong>简单性与准确性之间的平衡</strong>：
在SINDy中，达到简单性与准确性之间的平衡是一个微妙且关键的步骤。虽然添加更复杂的候选函数可以提高近似精度，但可能导致过拟合，并产生难以物理解释的项。例如，像\(\sin(\exp(t^{\tan(\exp(t^4))}))\)这样的项可能改善拟合但缺乏物理意义和可解释性。目标是找到一个中间地带，使模型既准确又可解释，从而提供对系统动力学的有意义见解。</p>
  </li>
  <li>
    <p><strong>代码仓库</strong>：本项目的完整代码可在<a href="https://github.com/henryli121/SINDy-govern-equation-.git">GitHub</a>上找到。</p>
  </li>
  <li>
    <p><strong>原始报告</strong>：以上报告是基于我的原始英文研究报告并由ChatGPT-4o提供翻译。请通过<a href="https://henryli121.github.io/henry.github.io/research/2024/07/11/01/">此处</a>查看更准确的措辞和解释。</p>
  </li>
</ol>]]></content><author><name></name></author><category term="create" /><summary type="html"><![CDATA[介绍]]></summary></entry><entry xml:lang="en"><title type="html">Identification of Nonlinear Dynamics (SINDy) to Time-Series Data</title><link href="http://localhost:4000/henry.github.io/research/2024/07/11/01/" rel="alternate" type="text/html" title="Identification of Nonlinear Dynamics (SINDy) to Time-Series Data" /><published>2024-07-11T19:00:00+08:00</published><updated>2024-07-11T19:00:00+08:00</updated><id>http://localhost:4000/henry.github.io/research/2024/07/11/01</id><content type="html" xml:base="http://localhost:4000/henry.github.io/research/2024/07/11/01/"><![CDATA[<div class="quote-box">
  <p><b>Introduction</b></p>
</div>

<p>This project employs the Sparse Identification of Nonlinear Dynamics (SINDy) algorithm to identify governing equations from time-series data of three features related to fluid and gas dynamics. The data is from my previous project titled “<a href="/henry.github.io/assets/papers/Backpropagation.pdf">Enhanced Feature Prediction in Time-Series Data Using a Structured Learning Approach</a>”. The three features analyzed are: Velocity of Fluid at Output 1, Mass Flow Rate of Gas at Output 1, and Velocity of Gas at Output 2. Using the SINDy algorithm, we reconstruct the underlying mathematical models governing these features by constructing a library of candidate functions, using sparse regression to identify the most relevant terms, and validating the identified equations against the observed data. This project demonstrates the effectiveness of SINDy in discovering simple, interpretable models from complex time-series data, enhancing our understanding of fluid and gas dynamics.</p>

<div class="quote-box">
  <p><b>Model Explanation: Sparse Identification of Nonlinear Dynamics (SINDy) Algorithm</b></p>
</div>

<p>Sparse Identification of Nonlinear Dynamics (SINDy) is an algorithm designed to discover parsimonious models that describe dynamical systems using a small number of terms from a large library of candidate functions. The approach combines the principles of sparse regression with a systematic library of nonlinear functions to identify the governing equations of the system from time-series data.</p>

<h3 id="mathematical-formulation">Mathematical Formulation</h3>

<p>Consider a dynamical system described by the ordinary differential equation (ODE):</p>

\[\frac{d\mathbf{x}}{dt} = \mathbf{f}(\mathbf{x})\]

<p>where \(\mathbf{x} \in \mathbb{R}^n\) is the state vector of the system and \(\mathbf{f}\) represents the nonlinear dynamics.</p>

<p>The goal of SINDy is to approximate the function \(\mathbf{f}\) by a sparse linear combination of candidate functions from a predefined library. The process involves the following steps:</p>

<ol>
  <li>
    <p><strong>Data Collection</strong>:
Collect time-series data for the state variables \(\mathbf{x}(t)\). Let \(\mathbf{X}\) be the matrix containing these measurements, where each column corresponds to a different state variable and each row corresponds to a different time point.</p>
  </li>
  <li>
    <p><strong>Library Construction</strong>:
Construct a library \(\mathbf{\Theta}(\mathbf{X})\) of candidate functions. The library includes various nonlinear functions of the state variables, such as polynomials, trigonometric functions, and exponentials. Mathematically, the library can be represented as:</p>

\[\mathbf{\Theta}(\mathbf{X}) = [\mathbf{1}, \mathbf{X}, \mathbf{X}^2, \sin(\mathbf{X}), \cos(\mathbf{X}), \exp(\mathbf{X}), \mathbf{X} \exp(\mathbf{X}), \ldots],\]

    <p>where each column of \(\mathbf{\Theta}\) represents a different candidate function.</p>
  </li>
  <li>
    <p><strong>Sparse Regression</strong>:
For each state variable \(x_i\) express the time derivative \(\frac{dx_i}{dt}\) as a linear combination of the candidate functions in \(\mathbf{\Theta}(\mathbf{X})\):</p>

\[\frac{d\mathbf{X}}{dt} = \mathbf{\Theta}(\mathbf{X}) \mathbf{\Xi},\]

    <p>where \(\mathbf{\Xi}\) is a matrix of coefficients, with each column corresponding to a different state variable. The key idea is to enforce sparsity in \(\mathbf{\Xi}\), meaning that most of the coefficients should be zero. This can be achieved using sparse regression techniques such as the Least Absolute Shrinkage and Selection Operator (LASSO):</p>

\[\mathbf{\Xi} = \underset{\mathbf{\Xi}}{\operatorname{argmin}} \left\| \frac{d\mathbf{X}}{dt} - \mathbf{\Theta}(\mathbf{X}) \mathbf{\Xi} \right\|_2^2 + \lambda \left\| \mathbf{\Xi} \right\|_1,\]

    <p>where \(\lambda\) is a regularization parameter that controls the sparsity of the solution.</p>
  </li>
  <li>
    <p><strong>Model Identification</strong>:
The non-zero entries in the coefficient matrix \(\mathbf{\Xi}\) correspond to the terms in the library \(\mathbf{\Theta}(\mathbf{X})\) that are most relevant for describing the dynamics of the system. The identified model can be written as:</p>

\[\frac{dx_i}{dt} = \sum_{j} \xi_{ij} \theta_j(\mathbf{x}),\]

    <p>where \(\xi_{ij}\) are the non-zero coefficients and \(\theta_j(\mathbf{x})\) are the corresponding candidate functions.</p>
  </li>
</ol>

<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0711_1.JPG" alt="Image 1" />
   <br />
   <div class="caption">Schematic of the SINDy algorithm, demonstrated on the Lorenz equations</div>
</div>

<p>In summary, SINDy offers a powerful framework for identifying governing equations from data, providing insights into the dynamics of complex systems through sparse and interpretable models. You can read original SINDy Paper <a href="https://www.pnas.org/doi/pdf/10.1073/pnas.1517384113">here</a>.</p>

<div class="quote-box">
  <p><b>Data Processing</b></p>
</div>

<h3 id="preliminary">Preliminary</h3>

<p>The data analyzed in this project stems from a previous machine learning effort titled <a href="/henry.github.io/assets/papers/Backpropagation.pdf">“Enhanced Feature Prediction in Time-Series Data Using a Structured Learning Approach”</a>. This earlier project aimed to establish statistical relationships between selected features \(X = (X_1, X_2)\) and target features \(Y = (Y_1, Y_2, Y_3)\) using a combination of different models. The learning architecture involved three main stages: initial prediction, residual training, and model refinement. Through this parameter-focused approach, we obtained a prediction called \(Y_{\text{final}}\) of the target features with a relative MSE of 0.0005. However, these numerical predictions lack explanations and mathematical reasoning, especially in the last stage where we used a Multi-Layer Perceptron (MLP), which is often criticized as being a black box.</p>

<p>Hence, in this project, I aim to use SINDy to construct the approximation of governing equations for these results. Although the approximated governing equations may not provide results as accurate as those from the numerical model, I hope they can offer more mathematical reasoning for the results and enhance our understanding of fluid and gas dynamics.</p>

<p>The three features analyzed in the current SINDy project are:</p>

<ol>
  <li>
    <p><strong>Velocity of Fluid at Output 1</strong>: This feature represents the speed at which the fluid is moving at the first output point. It is crucial for understanding the dynamics and behavior of fluid flow within the system.</p>
  </li>
  <li>
    <p><strong>Mass Flow Rate of Gas at Output 1</strong>: This feature measures the mass of gas passing through the first output point per unit time. It is essential for evaluating the efficiency and performance of gas transport within the system.</p>
  </li>
  <li>
    <p><strong>Velocity of Gas at Output 2</strong>: This feature indicates the speed of gas flow at the second output point. It provides insights into the behavior of gas dynamics, which is critical for optimizing and controlling gas-related processes.</p>
  </li>
</ol>

<p>These features are recorded over a series of time steps, resulting in three columns of time-series data.</p>

<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0711_2.JPG" alt="Image 2" />
   <br />
   <div class="caption">Time-series plot for the three features</div>
</div>

<h3 id="candidate-choice">Candidate Choice</h3>

<p>To identify the governing equations for the three features, we construct a library of candidate functions. The chosen candidates are designed to capture a wide range of potential dynamics within the system. The library includes:</p>

<ol>
  <li>
    <p><strong>Constant term</strong>: Represents a constant value across all time steps, capturing any baseline level in the data. This term helps to account for any steady-state behavior or offset in the data.</p>
  </li>
  <li>
    <p><strong>Linear term \(t\)</strong>: Captures any linear trend in the data over time. This term is important for identifying any steady increase or decrease in the values, which might correspond to consistent acceleration or deceleration in the system.</p>
  </li>
  <li>
    <p><strong>Quadratic term \(t^2\)</strong>: Accounts for any quadratic or parabolic trends in the data. This term is useful for modeling acceleration or deceleration that changes over time, often seen in systems experiencing non-linear growth or decay.</p>
  </li>
  <li>
    <p><strong>Exponential term \(\exp(-t)\)</strong>: Models exponential decay, which is common in many physical and chemical processes such as radioactive decay, cooling, or damping in mechanical systems. The shape of this function rapidly decreases to zero as \(t\) increases, making it ideal for capturing processes that diminish over time.</p>
  </li>
  <li>
    <p><strong>Sine term \(\sin(t)\)</strong>: Captures periodic oscillations or cycles in the data, often present in systems with harmonic motion like waves, vibrations, or seasonal variations. The sine function is valuable for identifying cyclic behaviors that repeat over regular intervals.</p>
  </li>
  <li>
    <p><strong>Cosine term \(\cos(t)\)</strong>: Complements the sine term, capturing phase-shifted periodic behavior. While the sine term starts at zero, the cosine term starts at one, allowing for the capture of oscillatory behavior with different phases.</p>
  </li>
  <li>
    <p><strong>Interaction term \(t \cdot \exp(-t)\)</strong>: Represents a combination of linear and exponential dynamics, useful for modeling more complex interactions in the system. This term starts at zero, increases to a peak, and then decays, making it suitable for processes that initially grow and then decay over time.</p>
  </li>
</ol>

<p>These candidate functions are selected to provide a comprehensive while relatively simple basis for approximating the governing equations. Of course, you can select as many complex terms as you want to get a closer approximation; however, it is subtle to choose between interpretability and over-fitting.</p>

<div class="quote-box">
  <p><b>Network Setup and Training</b></p>
</div>

<ol>
  <li>
    <p><strong>Library Construction</strong>:
A library of candidate functions is constructed for each feature. The library includes constant, linear, quadratic, exponential, sine, cosine, and interaction terms. These candidate functions are chosen to capture a wide range of potential dynamics within the system.</p>
  </li>
  <li><strong>Data Splitting</strong>:
The data for each feature is split into three intervals:
    <ul>
      <li>Interval 1: \(t \in [0, 10)\)</li>
      <li>Interval 2: \(t \in [10, 600)\)</li>
      <li>Interval 3: \(t \in [600, 2000]\)</li>
    </ul>

    <p>Splitting the data into these intervals allows us to capture different dynamic behaviors that may occur over different time periods. Each interval is treated separately to ensure that the governing equations identified are specific to the dynamics within that interval, providing a more accurate and detailed understanding of the system’s behavior over time.</p>
  </li>
  <li><strong>Sparse Regression</strong>:
The LassoCV algorithm, a type of L1-regularized linear regression, is used to fit the data. This process involves:
    <ul>
      <li>Scaling the candidate functions to standardize the data.</li>
      <li>Performing cross-validation to determine the optimal regularization parameter (\(\lambda\)).</li>
      <li>Identifying the coefficients for the most significant terms in the governing equations, ensuring that the resulting model is both sparse and interpretable.</li>
    </ul>
  </li>
  <li><strong>Equation Construction</strong>:
For each interval and each feature, the identified coefficients and terms are combined to form the governing equations. These piecewise equations provide a detailed mathematical representation of the dynamics within each interval, enhancing our understanding of the fluid and gas dynamics by revealing the underlying processes that drive the observed behavior.</li>
</ol>

<div class="quote-box">
  <p><b>Experiment Results</b></p>
</div>
<p>The experimenting results are showing in the plot below:</p>

<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0711_3.JPG" alt="Image 3" />
   <br />
   <div class="caption">Identified govern-equations and their corresponding plots vs actual results</div>
</div>
<p>The experiment results compare the actual time-series data for each feature with the identified equations derived using the SINDy algorithm. The three features analyzed are: <i>Velocity of Fluid at Output 1</i>, <i>Mass Flow Rate of Gas at Output 1</i>, and <i>Velocity of Gas at Output 2</i>.</p>

<p>Overall, the identified equations capture the general trends and dynamic behaviors of the actual data. The SINDy algorithm effectively balances simplicity (interpretability) and accuracy (avoiding overfitting) by selecting a limited number of significant terms for the governing equations. This balance ensures that the model remains interpretable while providing a good approximation of the underlying dynamics.</p>

<p>In the plots, the identified piecewise equations are presented alongside the actual data. These equations offer a detailed mathematical representation of the system’s behavior within each interval. While there are some deviations between the identified and actual data, particularly in certain intervals, the overall fit is strong, demonstrating the effectiveness of the SINDy approach in capturing the essential dynamics of fluid and gas behaviors.</p>

<div class="quote-box">
  <p><b>Conclusion</b></p>
</div>
<p>In this project, we applied the Sparse Identification of Nonlinear Dynamics (SINDy) algorithm to identify governing equations for time-series data from a previous machine learning project. Several key points and reflections emerged from this study:</p>

<ol>
  <li>
    <p><strong>Candidate Choice is the Key</strong>:
Selecting appropriate candidate functions to build the library is the most crucial part of SINDy. The library directly impacts the effectiveness and accuracy of the identified equations. A well-chosen library allows the model to capture the essential dynamics of the system while maintaining interpretability.</p>
  </li>
  <li>
    <p><strong>Prior Knowledge of the System</strong>:
The success of SINDy heavily relies on prior knowledge of the system to select the right candidates. This presents a challenge in real-world scenarios where background information about the data may be limited or unavailable. The effectiveness of SINDy in such cases remains an open question, highlighting the need for further research and potential enhancements to the algorithm.</p>
  </li>
  <li>
    <p><strong>Balance Between Simplicity and Accuracy</strong>:
Achieving a balance between simplicity and accuracy is a subtle and critical step in SINDy. While adding more complex candidate functions can improve approximation accuracy, it may lead to overfitting and result in terms that are difficult to interpret physically. For instance, a term like \(\sin(\exp(t^{\tan(\exp(t^4))}))\) might improve fit but lacks physical meaning and interpretability. The goal is to find a middle ground where the model is both accurate and interpretable, providing meaningful insights into the system dynamics.</p>
  </li>
  <li>
    <p><strong>Code Repository:</strong> The complete code for this project is available on <a href="https://github.com/henryli121/SINDy-govern-equation-.git">GitHub</a>.</p>
  </li>
</ol>]]></content><author><name></name></author><category term="research" /><summary type="html"><![CDATA[Introduction]]></summary></entry><entry xml:lang="en"><title type="html">Enhanced Feature Prediction in Time-Series Data Using a Structured Learning Approach</title><link href="http://localhost:4000/henry.github.io/paper/2024/07/09/01/" rel="alternate" type="text/html" title="Enhanced Feature Prediction in Time-Series Data Using a Structured Learning Approach" /><published>2024-07-09T22:10:00+08:00</published><updated>2024-07-09T22:10:00+08:00</updated><id>http://localhost:4000/henry.github.io/paper/2024/07/09/01</id><content type="html" xml:base="http://localhost:4000/henry.github.io/paper/2024/07/09/01/"><![CDATA[]]></content><author><name></name></author><category term="paper" /><summary type="html"><![CDATA[]]></summary></entry><entry xml:lang="en"><title type="html">Contrastive Out-of-Distribution with Multi-modal Information for Document Classification</title><link href="http://localhost:4000/henry.github.io/paper/2024/06/19/02/" rel="alternate" type="text/html" title="Contrastive Out-of-Distribution with Multi-modal Information for Document Classification" /><published>2024-06-19T20:10:00+08:00</published><updated>2024-06-19T20:10:00+08:00</updated><id>http://localhost:4000/henry.github.io/paper/2024/06/19/02</id><content type="html" xml:base="http://localhost:4000/henry.github.io/paper/2024/06/19/02/"><![CDATA[]]></content><author><name></name></author><category term="paper" /><summary type="html"><![CDATA[]]></summary></entry><entry xml:lang="en"><title type="html">Training a Machine to Learn Different Languages</title><link href="http://localhost:4000/henry.github.io/research/2024/06/19/01/" rel="alternate" type="text/html" title="Training a Machine to Learn Different Languages" /><published>2024-06-19T20:00:00+08:00</published><updated>2024-06-19T20:00:00+08:00</updated><id>http://localhost:4000/henry.github.io/research/2024/06/19/01</id><content type="html" xml:base="http://localhost:4000/henry.github.io/research/2024/06/19/01/"><![CDATA[<div class="quote-box">
  <p><b>Introduction</b></p>
</div>

<p>Understanding and identifying languages from text inputs is a fundamental task in natural language processing, with applications in automatic translation and multilingual sentiment analysis. This project aims to develop a machine learning model to accurately identify the language of a given text snippet. We leverage Long Short-Term Memory (LSTM) networks, a type of recurrent neural network known for capturing long-term dependencies in sequential data. LSTMs maintain context over extended text sequences, making them ideal for understanding and processing human languages. This post details the process from data preparation and cleaning to training an LSTM-based model.</p>

<div class="quote-box">
  <p><b>Model Architecture: Long Short-Term Memory (LSTM)</b></p>
</div>

<p>Long Short-Term Memory (LSTM) networks are designed to address the vanishing gradient problem inherent in traditional RNNs, making them effective for handling long-term dependencies in sequential data.</p>

<p>The architecture of an LSTM cell involves a gating mechanism that includes a forget gate, an input gate, and an output gate. These gates regulate information flow, enabling the cell to maintain and update information over long sequences.</p>

<p>The internal operations of an LSTM cell can be described by the following equations:</p>

<ol>
  <li>
    <p><strong>Forget Gate:</strong> Determines which information from the previous cell state to discard:
\(f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)\)</p>
  </li>
  <li>
    <p><strong>Input Gate:</strong> Decides which new information to add to the cell state:
\(i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)\)
\(\tilde{C}_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C)\)</p>
  </li>
  <li>
    <p><strong>Cell State Update:</strong> Combines the old cell state, modified by the forget gate, with the new candidate values, scaled by the input gate:
\(C_t = f_t \cdot C_{t-1} + i_t \cdot \tilde{C}_t\)</p>
  </li>
  <li>
    <p><strong>Output Gate:</strong> Decides the next hidden state based on the updated cell state:
\(o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o)\)
\(h_t = o_t \cdot \tanh(C_t)\)</p>
  </li>
</ol>

<p>In these equations:</p>
<ul>
  <li>\(\sigma\) represents the sigmoid activation function.</li>
  <li>\(\tanh\) denotes the hyperbolic tangent function.</li>
  <li>\(W\) and \(b\) are the weight matrices and biases.</li>
  <li>\(h_t\) and \(C_t\) represent the hidden state and cell state at time step \(t\).</li>
</ul>

<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0620_1.JPG" alt="Image 1" />
   <br />
   <div class="caption">Figure 1: Diagram illustration of LSTM</div>
</div>

<p>LSTMs excel in language tasks due to their ability to retain context over extended sequences, making them a preferred choice for NLP applications such as language modeling, translation, and sentiment analysis.</p>

<div class="quote-box">
  <p><b>Data Collection and Cleaning</b></p>
</div>

<p>The initial step involved preparing a dataset comprising text samples from various languages. Ensuring the data was clean and well-structured was crucial for the model’s performance.</p>

<p>The data cleaning process involved identifying and removing unlabeled data, handling books with unusual names, stripping prefaces and postfaces, and filtering outliers. After cleaning, the dataset was balanced by selecting the top six languages and structured into a 3D tensor. The final processed data was saved in <code class="language-plaintext highlighter-rouge">.npy</code> files for efficient training.</p>

<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0620_2.JPG" alt="Image 2" />
   <br />
   <div class="caption">Figure 2: The format of an ebook</div>
</div>

<h3 id="data-cleaning-process">Data Cleaning Process</h3>

<p>Several critical steps were involved to ensure the dataset’s integrity and usability:</p>

<ol>
  <li><strong>Identification and Removal of Unlabeled Data:</strong> Manually identifying and removing books without clear language tags.</li>
  <li><strong>Handling Unusual Names:</strong> Manually reviewing books with non-standard naming formats to maintain consistency.</li>
  <li><strong>Stripping Prefaces and Postfaces:</strong> Removing prefaces and postfaces typically written in English to prevent language contamination.</li>
  <li><strong>Filtering Outliers:</strong> Removing books that did not align with the typical format.</li>
</ol>

<p>After these steps, the dataset was reduced to 36,082 books. To ensure balanced training, the top six languages with the highest number of samples were selected.</p>

<h3 id="data-distribution-and-structure">Data Distribution and Structure</h3>

<p>Post-cleaning, the dataset was structured into a 3D tensor. For each language and each book, random sequences of 30 consecutive characters were extracted and tokenized using one-hot encoding.</p>

<p>The 3D tensor can be represented as follows:</p>

\[\mathcal{X} = 
\begin{bmatrix}
\begin{bmatrix}
x_{0,0} &amp; x_{0,1} &amp; x_{0,2} \\
x_{1,0} &amp; x_{1,1} &amp; x_{1,2} \\
x_{2,0} &amp; x_{2,1} &amp; x_{2,2} 
\end{bmatrix} \\
\begin{bmatrix}
x_{0,0} &amp; x_{0,1} &amp; x_{0,2} \\
x_{1,0} &amp; x_{1,1} &amp; x_{1,2} \\
x_{2,0} &amp; x_{2,1} &amp; x_{2,2} 
\end{bmatrix} \\
\begin{bmatrix}
x_{0,0} &amp; x_{0,1} &amp; x_{0,2} \\
x_{1,0} &amp; x_{1,1} &amp; x_{1,2} \\
x_{2,0} &amp; x_{2,1} &amp; x_{2,2} 
\end{bmatrix}
\end{bmatrix}
=
\begin{bmatrix}
\begin{bmatrix}
\vec{x}_0 \\
\vec{x}_1 \\
\vec{x}_2 
\end{bmatrix} \\
\begin{bmatrix}
\vec{x}_0 \\
\vec{x}_1 \\
\vec{x}_2 
\end{bmatrix} \\
\begin{bmatrix}
\vec{x}_0 \\
\vec{x}_1 \\
\vec{x}_2 
\end{bmatrix} \\
\end{bmatrix}
=
\begin{bmatrix}
X_0 \\
X_1 \\
X_2 
\end{bmatrix}\]

<h3 id="saving-processed-data">Saving Processed Data</h3>

<p>The final processed data was saved into <code class="language-plaintext highlighter-rouge">.npy</code> files:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">X_input</code>: Contained the input sequences.</li>
  <li><code class="language-plaintext highlighter-rouge">Y_input</code>: Contained the corresponding language labels.</li>
</ul>

<div class="quote-box">
  <p><b>Network Setup and Training</b></p>
</div>

<p>The core of this project is the LSTM network, designed to process sequences of text data. The network architecture consists of an embedding layer, followed by two LSTM layers, and dense layers for classification.</p>

<h3 id="network-structure">Network Structure</h3>

<ul>
  <li><strong>Embedding Layer:</strong> Converts input tokens into dense vectors of fixed size.</li>
  <li><strong>LSTM Layers:</strong> Two LSTM layers, the first with 128 cells and the second with 64 cells, process the embeddings and capture temporal dependencies in the text sequences.</li>
  <li><strong>Dense Layer:</strong> Outputs the probability distribution over the possible languages using a softmax activation function.</li>
</ul>

<h3 id="training-process">Training Process</h3>

<p>The network was trained using a categorical cross-entropy loss function and the Adam optimizer. The performance of the model was monitored on the validation set to prevent overfitting. Training and validation accuracy metrics were tracked to evaluate the model’s learning progress.</p>

<p>Here are the results after 14 epochs of training:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 14/15
782/782 <span class="o">[==============================]</span> - 91s 116ms/step - loss: 0.1281 - accuracy: 0.9647 - val_loss: 0.1356 - val_accuracy: 0.9590
</code></pre></div></div>
<p>That’s 96% accuracy.</p>

<div class="quote-box">
  <p><b>Example Interaction</b></p>
</div>

<p>After training, the tokenized map and the model were saved for easy import in future sessions. When an input sentence is provided, the program takes a sequence of 30 characters, tokenizes them according to the saved mapping, and uses the trained model to predict the language category.</p>

<p>Let’s see the model in action with an example:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> Enter your sentence:
<span class="o">&gt;&gt;&gt;</span> Successful coaches at powerhouses have traditionally stayed put, <span class="s2">"lording over fiefdoms until they lost their winning magic or were undone by age or scandal,"</span>
<span class="o">&gt;&gt;&gt;</span> It is English
</code></pre></div></div>

<div class="quote-box">
  <p><b>Conclusion</b></p>
</div>

<p>Key points include:</p>
<ul>
  <li><strong>Examining Original Data Format:</strong> Understanding the original format of the eBooks was crucial for identifying useful data sections, such as distinguishing headers and footers from the main content.</li>
  <li><strong>Manual Data Cleaning:</strong> Manually removing unlabeled data and non-standard book names ensured the integrity of the dataset, which is vital for training an accurate model.</li>
  <li><strong>Balancing the Dataset:</strong> Selecting the top six languages helped maintain a balanced dataset, which is essential for preventing bias and ensuring model generalizability.</li>
  <li><strong>Efficient Data Structuring:</strong> Tokenizing sequences into a 3D tensor using one-hot encoding was pivotal for preparing the data for the LSTM network.</li>
  <li><strong>Understanding LSTM Foundations:</strong> While LSTM is relatively old compared to current popular NLP models like Transformers, it forms the foundation of most modern NLP models. Understanding and implementing LSTM helps in grasping the internal mechanisms of how machines work with sequential data.</li>
  <li><strong>Code Repository:</strong> The complete code for this project is available on <a href="https://github.com/henryli121/language-identifier">GitHub</a>.</li>
</ul>]]></content><author><name></name></author><category term="research" /><summary type="html"><![CDATA[Introduction]]></summary></entry><entry xml:lang="en"><title type="html">Proofs for the Four Fundamental Equations of the Backpropagation and Algorithms in Feedforward Neural Networks</title><link href="http://localhost:4000/henry.github.io/paper/2024/06/18/01/" rel="alternate" type="text/html" title="Proofs for the Four Fundamental Equations of the Backpropagation and Algorithms in Feedforward Neural Networks" /><published>2024-06-18T22:40:00+08:00</published><updated>2024-06-18T22:40:00+08:00</updated><id>http://localhost:4000/henry.github.io/paper/2024/06/18/01</id><content type="html" xml:base="http://localhost:4000/henry.github.io/paper/2024/06/18/01/"><![CDATA[]]></content><author><name></name></author><category term="paper" /><summary type="html"><![CDATA[]]></summary></entry><entry xml:lang="zh"><title type="html">什么是音乐？</title><link href="http://localhost:4000/henry.github.io/blog/2024/06/07/01/" rel="alternate" type="text/html" title="什么是音乐？" /><published>2024-06-07T16:00:00+08:00</published><updated>2024-06-07T16:00:00+08:00</updated><id>http://localhost:4000/henry.github.io/blog/2024/06/07/01</id><content type="html" xml:base="http://localhost:4000/henry.github.io/blog/2024/06/07/01/"><![CDATA[<div class="final-quote">
音，声也。生于心，有节于外，谓之音。
<br />
<p style="font-size:13px;" align="right">  - 许慎《说文解字·音部》 </p> 
</div>
<p>“音是声音的一种。产生于内心，有节奏地表现出来后，叫做音乐。” 这是许慎在东汉时期就给出的定义。“生于心”，听着挺玄乎，但貌似有道理。其实，音乐的起源一直是一个谜，现在主流的说法主要有三种。</p>

<div class="quote-box">
  <p>音乐的起源</p>
</div>
<p><b>语言→音乐：</b>
<br />支持语言产生音乐的主要是考古学家。他们通过古代遗迹发现文字普遍出现的更早，因此，由于语言的表达方式不同，有的表达渐渐地演化成了我们所说的音乐。
<br />
<b>音乐→语言：</b>
<br />支持音乐产生语言的主要是人类学家。他们通过研究古老的部落发现，尽管一些部落还没有完整的语言系统，但是已经产生了通过音乐交流的途径。
<br />
最后一种说法就是：音乐和语言同时产生。</p>
<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0607_01.JPG" alt="Image 1" />
</div>

<div class="quote-box">
  <p>音乐和语言的差别</p>
</div>
<p>语言和音乐存在很大的不同，其中两个最大的差别就是<b>方向性</b>和<b>重复性</b>。</p>

<ul>
  <li>方向性：
语言有明显的方向性。一句完整的话有特定的主语和宾语，这明确表明了人物的指向。而且，语言要在两个人都会同一门语言的前提下，传递信息的功能才能实现。相反，音乐则没有明确的方向性。任何人都可以不同的形式和不同的理解接受一段旋律。正所谓：音乐无国界。<br /></li>
  <li>重复性:
语言和音乐都有重复，但是他们的功能完全不同。语言的重复是发生在当对方没有听懂和想强调自己的话时。但是音乐的重复目的是在<b>为了扩大情感的共鸣</b>。</li>
</ul>
<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0607_02.JPG" alt="Image 2" />
</div>

<div class="quote-box">
  <p>音乐和语言的功能</p>
</div>
<p>所以，简单的总结一下， 语言的功能是：<b>传递信息</b>；音乐的功能是：<b>传递感情</b>。<br />
那现在不妨让我们把思维再打开一些：<br />
什么是传递信息？无非就是一个物体产生信息，然后另一个物体接受信息。并且这只存在：0（未接受）和1（接受）这两种可能性。比如：当我们使用电脑，这就是一种信息的传递，而我们使用的就是计算机语言：0和1。因此，基于程序的人工智能在过去的几年便轻松攻破了人类的语言体系。<br />
什么是传递感情？这个问题显然宽泛。但是，如果我们想象信息是一种0和1的状态话，不难想象，情感就是0和1的<b>纠缠态</b>。比如，我们不会说我完全接受/未接受这个感情。但是，我们会说我又爱你，又恨你。这就是感情的不确定性。因此，即便如今的人工智能可以根据乐理来创作音乐，但是在人类看来那始终是缺乏情感的。</p>
<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0607_03.JPG" alt="Image 3" />
</div>

<div class="quote-box">
  <p>音乐是什么</p>
</div>
<p>最后，我不妨回答我们文章最开始的那个问题：音乐是什么？<br />
如果说音乐的功能是为了传递纠缠态的感情，那么音乐一定是更高纬度的产物。就像我们现在还无法理解量子纠缠一样。而我们所说的歌曲，旋律，仅仅是音乐在我们三维世界上的投影。所以，<b>现在人类还无法完全的理解音乐</b>。<br />
但是，我们人类有个有意思的特点，那就是当我们无法解释一个现象时，把它推给上帝，一切就解释得通了。在大多数宗教里都有天使这个概念：天使本意为上天的使者。上帝的使者，他也是离上帝最近的人。而天使的作用就是将神的讯息传递给人类，并且记录下人类的活动然后汇报给上帝。但是，为什么上帝不自己给人类说呢，一定要让天使说呢？因为人类根本无法理解上帝的语言，上帝生活在更高的纬度。因此，我们需要天使这个翻译，来翻译上帝的语言，而这个无法理解的高纬度语言就是音乐。<br /></p>
<div class="image-container">
  <img src="/henry.github.io/assets/blog_images/0607_04.JPG" alt="Image 4" />
</div>
<p>最后再来解读柏拉图这句对音乐看法：“<b>音乐是道德的法则。它给予宇宙灵魂，思想翅膀，想象飞翔，赋予生活欢乐和一切。</b>”也许，这就是上帝的意义吧。</p>]]></content><author><name></name></author><category term="blog" /><summary type="html"><![CDATA[音，声也。生于心，有节于外，谓之音。 - 许慎《说文解字·音部》 “音是声音的一种。产生于内心，有节奏地表现出来后，叫做音乐。” 这是许慎在东汉时期就给出的定义。“生于心”，听着挺玄乎，但貌似有道理。其实，音乐的起源一直是一个谜，现在主流的说法主要有三种。]]></summary></entry><entry xml:lang="zh"><title type="html">从零开始创建个人网站的旅程</title><link href="http://localhost:4000/henry.github.io/create/2024/05/30/website-creation/" rel="alternate" type="text/html" title="从零开始创建个人网站的旅程" /><published>2024-05-30T17:00:00+08:00</published><updated>2024-05-30T17:00:00+08:00</updated><id>http://localhost:4000/henry.github.io/create/2024/05/30/website-creation</id><content type="html" xml:base="http://localhost:4000/henry.github.io/create/2024/05/30/website-creation/"><![CDATA[<h3 id="引言">引言</h3>

<p>欢迎来到我的创作页面！在这篇博文中，我将与大家分享我是如何从零开始创建这个网站的全过程。希望这段经历能对那些也在尝试自己动手搭建网站的朋友们有所帮助。</p>

<div class="quote-box">
  <p>Github Pages 网站设置</p>
</div>

<p><strong>选择平台与框架</strong></p>
<ul>
  <li>经过一番研究，我决定使用 GitHub Pages 和 Jekyll 来搭建我的个人网站。Jekyll 是一个简单、博客友好的静态网站生成器，非常适合像我这样的初学者。</li>
</ul>

<p><strong>初始设置</strong></p>
<ul>
  <li>首先，我在 GitHub 上创建了一个新的仓库，并克隆到本地。使用以下命令完成克隆：
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/henryli121/henry.github.io.git
</code></pre></div>    </div>
  </li>
  <li>接着，我安装了 Jekyll 和 Bundler，通过命令行工具初始化了 Jekyll 项目：
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gem <span class="nb">install </span>jekyll bundler
jekyll new my-awesome-site
<span class="nb">cd </span>my-awesome-site
bundle <span class="nb">exec </span>jekyll serve
</code></pre></div>    </div>
  </li>
  <li>在初始化过程中，我遇到了 gem 安装失败的问题，通过更新 RubyGems 和使用 sudo 命令解决了这个问题：
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gem update <span class="nt">--system</span>
<span class="nb">sudo </span>gem <span class="nb">install </span>jekyll bundler
</code></pre></div>    </div>
  </li>
</ul>

<p><strong>初次构建</strong></p>
<ul>
  <li>使用 Jekyll 生成的默认模板，我成功地构建了第一个版本的网站，并通过 GitHub Pages 发布到网上：
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bundle <span class="nb">exec </span>jekyll serve
</code></pre></div>    </div>
  </li>
  <li>在构建过程中，我遇到了 Jekyll 版本不兼容的问题，通过指定特定版本的 Jekyll 解决了这个问题：
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gem <span class="s1">'jekyll'</span>, <span class="s1">'~&gt; 4.2.0'</span>
bundle <span class="nb">install</span>
</code></pre></div>    </div>
  </li>
</ul>

<div class="quote-box">
  <p>博客创建部分</p>
</div>

<p><strong>配置 _config.yml</strong></p>
<ul>
  <li>网站初次构建成功后，我开始修改 <code class="language-plaintext highlighter-rouge">_config.yml</code> 文件，以自定义网站的基本信息，包括站点标题、描述、导航链接等。</li>
</ul>

<p><strong>目录结构调整</strong></p>
<ul>
  <li>按照 Jekyll 的规范，我调整了项目的目录结构，确保所有文件和资源都在正确的位置上。以下是我的当前目录结构：</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.
├── _config.yml
├── _site
├── _includes
│   ├── head.html
│   └── footer.html
├── _layouts
│   ├── base.html
│   ├── home.html
│   ├── page.html
│   └── post.html
├── _posts
│   └── 2024-05-26-test.md
├── assets
│   ├── blog_images
│   ├── css
│   │   ├── gallery.css
│   │   ├── lightbox.css
│   │   ├── main.css
│   │   ├── main.css.map
│   ├── images
│   └── js
├── pic.md
├── about.md
├── blog.md
├── creation.md
└── other files
</code></pre></div></div>

<p><strong>版本控制</strong></p>
<ul>
  <li>每次做出修改后，我都会使用 Git 进行版本控制，并将更新推送到 GitHub 上。这样可以方便地追踪历史变更，并在必要时恢复到之前的版本：
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git add <span class="nb">.</span>
git commit <span class="nt">-m</span> <span class="s2">"Initial commit"</span>
git push origin main
</code></pre></div>    </div>
  </li>
</ul>

<div class="quote-box">
  <p>使用 Lightbox2 实现图片展示</p>
</div>

<p><strong>引入 Lightbox2</strong></p>
<ul>
  <li>为了更好地展示图片，我决定使用 Lightbox2 插件。这个插件可以让用户点击图片时显示大图，并添加图片标题。</li>
</ul>

<p><strong>安装与配置</strong></p>
<ul>
  <li>我按照 Lightbox2 的文档，将相关的 CSS 和 JS 文件引入到项目中。然而，在实现过程中遇到了标题无法正常显示的问题。经过一番排查，发现是由于 Lightbox2 的某些配置与我的项目结构不兼容。最终，通过添加 jQuery 解决了这个问题：
    <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;script </span><span class="na">src=</span><span class="s">"https://code.jquery.com/jquery-3.6.0.min.js"</span><span class="nt">&gt;&lt;/script&gt;</span>
</code></pre></div>    </div>
  </li>
</ul>

<div class="quote-box">
  <p>调试与优化</p>
</div>

<p><strong>调试工具的使用</strong></p>
<ul>
  <li>在开发过程中，我频繁使用浏览器的开发者工具（如 Chrome DevTools）来调试和检查页面元素、样式以及脚本错误。这对定位问题和优化性能非常有帮助。</li>
</ul>

<p><strong>常见错误与解决方案</strong></p>

<p><strong>目录结构问题</strong></p>
<ul>
  <li>
    <p>项目目录结构不清晰可能导致资源文件无法正确加载。确保所有文件和资源都在正确的位置上，如 <code class="language-plaintext highlighter-rouge">_includes</code> 文件夹中的 <code class="language-plaintext highlighter-rouge">head.html</code> 和 <code class="language-plaintext highlighter-rouge">footer.html</code>，以及 <code class="language-plaintext highlighter-rouge">_layouts</code> 文件夹中的其他 HTML 文件。</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">_site</code> 文件夹用于存储 Jekyll 构建后的静态网站文件，每次构建时都会被重新生成。因此，任何修改都应该在源文件中完成，而不是直接修改 <code class="language-plaintext highlighter-rouge">_site</code> 中的文件。</p>
  </li>
</ul>

<p><strong>资源文件路径</strong></p>
<ul>
  <li>在使用资源文件（如图片、CSS、JS）时，确保使用相对路径，这样在本地和 GitHub Pages 上都能正常工作。例如：
    <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;link</span> <span class="na">rel=</span><span class="s">"stylesheet"</span> <span class="na">href=</span><span class="s">"/henry.github.io/assets/css/main.css"</span><span class="nt">&gt;</span>
<span class="nt">&lt;script </span><span class="na">src=</span><span class="s">"/henry.github.io/assets/js/lightbox.js"</span><span class="nt">&gt;&lt;/script&gt;</span>
</code></pre></div>    </div>
  </li>
</ul>

<p><strong>其他问题</strong></p>
<ul>
  <li>文件路径错误：确保所有资源文件都在正确的路径下，避免使用绝对路径。</li>
  <li>缓存问题：每次更新后清除浏览器缓存，确保加载到的是最新版本的文件：
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bundle <span class="nb">exec </span>jekyll clean
bundle <span class="nb">exec </span>jekyll serve
</code></pre></div>    </div>
  </li>
  <li>兼容性问题：检查不同浏览器下的显示效果，确保网站在主流浏览器中都能正常工作。</li>
</ul>

<p><strong>遇到的其他问题</strong></p>
<ul>
  <li>在实现一些特定功能时，比如创建博客页面和添加社交媒体按钮，遇到了样式问题和 JavaScript 错误。通过不断调试和查阅文档，最终解决了这些问题。</li>
</ul>

<h3 id="复盘">复盘</h3>
<p>其实，在使用 Jekyll 搭建我的个人网站之前，我也尝试过市面上其他的平台，比如 WordPress 和 Wix，但它们都有进阶内容付费、自主性低的问题。所以我决定从源代码开始写网站。通过这次从零开始的搭建经历，我最感到吃惊的是现在编程学习或者网络技术学习的成本之低。</p>

<p>在开始这个项目之前，我从未接触过 HTML 和 CSS。于是抱着尝试的态度，我开始了这个项目。当然，敢于继续下去的另一个原因是 <b>ChatGPT-4o</b>。毫不夸张地说，这个网页80%的代码都是 ChatGPT 帮我写的，它就像一个得力的助手，虽然称不上老师，但已足够优秀。当然，它不可能一口气全部帮你写出来，更多的是你和它的合作。在这个项目中，我关注的是整体的逻辑步骤，比如：如何搭建一个最基本的框架，然后逐步加入细节的调整，再进行优化和美化。我需要把这些步骤拆分成一个个小任务，再让 ChatGPT 来帮我写。一个个小任务的完成，最终搭建出了整个网站。</p>

<p>相对于几十年前动辄几个月的编程课程，现在在 AI 技术的加持下，编程学习或者网络技术学习的成本已经非常低。到网站目前这个状态，一共也就花费了我两天的时间。甚至这篇博文的大部分内容也是 ChatGPT 帮我总结的，因为它能够记住从项目开始以来我们之间的对话。因此，我只需要告诉它：“帮我把这个项目的过程写成一篇博客，名字叫‘从零开始创建个人网站的旅程’。”于是，15秒的时间这篇文章就写好了。至于哪些部分是我写的，就留给你们去猜测吧。</p>

<h3 id="结语">结语</h3>

<p>创建这个网站的过程充满了挑战与乐趣。从最初的框架选择，到中途的各种问题排查，再到最后的调试优化，每一步都是一次学习和成长的机会。希望通过这篇博文，能为同样在搭建网站道路上的你提供一些启发和帮助。</p>

<p>如果你在网站创建过程中遇到了类似的问题，欢迎留言，我们可以一起讨论和解决。谢谢阅读！</p>]]></content><author><name></name></author><category term="create" /><summary type="html"><![CDATA[引言]]></summary></entry></feed>